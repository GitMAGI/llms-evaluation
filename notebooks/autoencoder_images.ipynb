{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work-around for loading a module from a parent folder in Jupyter/Notebooks\n",
    "parent_dir = os.path.abspath(os.path.join('..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "from modules.autoencoders import VanillaAutoencoder, ConvolutedAutoencoder, VariationalAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "train_ds, test_ds = tfds.load('mnist', split=['train', 'test'], shuffle_files=True, batch_size=-1, as_supervised=True)\n",
    "x_train, y_train = tfds.as_numpy(train_ds)\n",
    "x_test, y_test = tfds.as_numpy(test_ds)\n",
    "#x_train = x_train[:,:,:,0]\n",
    "#x_test = x_test[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizzazione dei pixel a [0, 1]\n",
    "norm_x_train = x_train.astype('float32') / 255.\n",
    "norm_x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troviamo le classi presenti (da 0 a 9)\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)\n",
    "samples_per_class = 10  # Numero di esempi per classe da visualizzare\n",
    "\n",
    "# Creiamo una griglia di subplot: righe = n_classes, colonne = samples_per_class\n",
    "fig, axes = plt.subplots(n_classes, samples_per_class, figsize=(samples_per_class * 1, n_classes * 1))\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    # Trova gli indici degli esempi per la classe corrente\n",
    "    idxs = np.where(y_train == cls)[0]    \n",
    "    # Mostra l'etichetta sulla prima colonna di ogni riga\n",
    "    axes[i, 0].set_title(f\"Class {cls}\")\n",
    "    j=0    \n",
    "    # Seleziona randomicamente samples_per_class indici tra quelli della classe corrente\n",
    "    for idx in random.sample(list(idxs), samples_per_class):\n",
    "        # Seleziona l'immagine\n",
    "        img = x_train[idx]\n",
    "        # Visualizza l'immagine\n",
    "        axes[i, j].imshow(img, cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "        j=j+1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(immagine, titolo=\"Sampled Image\", figsize=(4,4)):\n",
    "    \"\"\"\n",
    "    Plotta una immagine, convertendola se necessario da vettoriale (784,) a matrice (28,28).\n",
    "\n",
    "    Parametri:\n",
    "    - immagine: numpy array rappresentante l'immagine (forma (784,) o (28,28))\n",
    "    - titolo: titolo da visualizzare sul plot\n",
    "    \"\"\"\n",
    "    # Se l'immagine è un vettore piatto, la rimodelliamo in 28x28\n",
    "    if immagine.ndim == 1 or (immagine.ndim == 2 and immagine.shape[0] * immagine.shape[1] == 784):\n",
    "        immagine = immagine.reshape(28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(immagine, cmap='gray')\n",
    "    plt.title(titolo)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encoding_tsne(encoder, data, labels, sample_size=None, perplexity=30, random_state=42, title=\"t-SNE projection of the latent space\"):\n",
    "    \"\"\"\n",
    "    Calcola l'encoding dei dati con il modello encoder e proietta le rappresentazioni latenti in 2D\n",
    "    utilizzando t-SNE. I punti sono colorati in modo discreto in base alle etichette (classi).\n",
    "\n",
    "    Parametri:\n",
    "    - encoder: modello Keras per ottenere l'encoding.\n",
    "    - dati: array dei dati in input (es. immagini).\n",
    "    - labels: array delle etichette corrispondenti.\n",
    "    - sample_size: (opzionale) numero di campioni da utilizzare per t-SNE (se None usa tutti i dati).\n",
    "    - perplexity: parametro perplexity per t-SNE.\n",
    "    - random_state: seme per la riproducibilità.\n",
    "    \"\"\"\n",
    "    # Se sample_size è definito e minore del numero totale di dati, campiona casualmente\n",
    "    if sample_size is not None and sample_size < len(data):\n",
    "        idx = np.random.choice(len(data), size=sample_size, replace=False)\n",
    "        data = data[idx]\n",
    "        labels = labels[idx]\n",
    "\n",
    "    # Calcola l'encoding dei dati\n",
    "    _predicted_ = encoder.predict(data)\n",
    "    if type(_predicted_) == list:\n",
    "        latent = _predicted_[0]\n",
    "    else:\n",
    "        latent = _predicted_\n",
    "\n",
    "    # Riduci a 2 dimensioni con t-SNE\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=random_state)\n",
    "    latent_2d = tsne.fit_transform(latent)\n",
    "\n",
    "    # Ottieni le etichette uniche\n",
    "    unique_labels = np.unique(labels)\n",
    "    # Se ci sono al massimo 10 classi, usiamo 'tab10', altrimenti 'tab20'\n",
    "    if len(unique_labels) <= 10:\n",
    "        cmap = plt.get_cmap('tab10', len(unique_labels))\n",
    "    else:\n",
    "        cmap = plt.get_cmap('tab20', len(unique_labels))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Plot separato per ogni classe con colori distinti\n",
    "    for i, ul in enumerate(unique_labels):\n",
    "        idx = labels == ul\n",
    "        plt.scatter(latent_2d[idx, 0], latent_2d[idx, 1],\n",
    "                    color=cmap(i), label=str(ul), s=5)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"t-SNE 1\")\n",
    "    plt.ylabel(\"t-SNE 2\")\n",
    "    plt.legend(title='Classe')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = \"20250320_175412\"\n",
    "model_path = os.path.join(\"..\", \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_x_train = norm_x_train.reshape((len(norm_x_train), -1))\n",
    "flatten_x_test = norm_x_test.reshape((len(norm_x_test), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = flatten_x_train.shape[1]\n",
    "neurons=(128, 64, 32)\n",
    "activations=('relu', 'relu', 'relu')\n",
    "latent_space_dim=2\n",
    "\n",
    "vannilla_model_type = VanillaAutoencoder.__name__\n",
    "\n",
    "vanilla_model_params_path = os.path.join(model_path, f\"{vannilla_model_type}_{model_name}.parameters.pkl\")\n",
    "vanilla_model_weights_path = os.path.join(model_path, f\"{vannilla_model_type}_{model_name}.weights.h5\")\n",
    "if not os.path.exists(vanilla_model_params_path) or not os.path.exists(vanilla_model_weights_path):\n",
    "    vanilla_model = VanillaAutoencoder(input_dim=input_dim, neurons=neurons, activations=activations, latent_space_dim=latent_space_dim, model_name=model_name)\n",
    "    optimizer = tf.keras.optimizers.get(\"Adam\")\n",
    "    optimizer.learning_rate.assign(.0001)\n",
    "    vanilla_model.compile(optimizer=optimizer, loss='mse')\n",
    "else:\n",
    "    vanilla_model = VanillaAutoencoder.load(model_path, model_name)\n",
    "\n",
    "vanilla_model.print_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(vanilla_model_params_path) or not os.path.exists(vanilla_model_weights_path):\n",
    "    history = vanilla_model.train(\n",
    "                flatten_x_train, \n",
    "                flatten_x_test,\n",
    "                epochs=10,\n",
    "                batch_size=512,\n",
    "                shuffle=True)\n",
    "else:\n",
    "    history = vanilla_model.get_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(vanilla_model_params_path) or not os.path.exists(vanilla_model_weights_path):\n",
    "    vanilla_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_encoder = vanilla_model.get_encoder()\n",
    "vanilla_decoder = vanilla_model.get_decoder()\n",
    "vanilla_autoencoder = vanilla_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss (Vanilla)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Calcolo delle statistiche dello spazio latente\n",
    "# (utilizzato per il sampling)\n",
    "# -------------------------------\n",
    "latent_reps = vanilla_encoder.predict(flatten_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_mean = np.mean(latent_reps, axis=0)\n",
    "latent_std = np.std(latent_reps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_img = np.random.normal(loc=latent_mean, scale=latent_std, size=(1,latent_space_dim))\n",
    "# Decodifica per ottenere la ricostruzione\n",
    "decoded_img = vanilla_decoder.predict(encoded_img)\n",
    "# Genera una nuova immagine\n",
    "plot_img(decoded_img, figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encoding_tsne(vanilla_encoder, flatten_x_test, y_test, sample_size=1000, title=f\"t-SNE projection of the latent space (Vanilla Encoder)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convoluted Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_input_shape = (norm_x_train.shape[1:][0], norm_x_train.shape[1:][1], 1)\n",
    "conv_filters=(32, 64, 64, 64)\n",
    "conv_activations=('relu', 'relu', 'relu', 'relu')\n",
    "conv_kernels=(3, 3, 3, 3)\n",
    "conv_strides=(1, 2, 2, 1)\n",
    "conv_latent_space_dim=2\n",
    "\n",
    "conv_model_type = ConvolutedAutoencoder.__name__\n",
    "\n",
    "conv_model_params_path = os.path.join(model_path, f\"{conv_model_type}_{model_name}.parameters.pkl\")\n",
    "conv_model_weights_path = os.path.join(model_path, f\"{conv_model_type}_{model_name}.weights.h5\")\n",
    "if not os.path.exists(conv_model_params_path) or not os.path.exists(conv_model_weights_path):\n",
    "    conv_model = ConvolutedAutoencoder(\n",
    "        input_shape=conv_input_shape, \n",
    "        filters=conv_filters, \n",
    "        kernels=conv_kernels, \n",
    "        strides=conv_strides, \n",
    "        activations=conv_activations,\n",
    "        latent_space_dim=conv_latent_space_dim,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.get(\"Adam\")\n",
    "    optimizer.learning_rate.assign(.0001)\n",
    "    conv_model.compile(optimizer=optimizer, loss='mse')\n",
    "else:\n",
    "    conv_model = ConvolutedAutoencoder.load(model_path, model_name)\n",
    "\n",
    "conv_model.print_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.run_functions_eagerly(False)\n",
    "if not os.path.exists(conv_model_params_path) or not os.path.exists(conv_model_weights_path):\n",
    "    conv_history = conv_model.train(\n",
    "                norm_x_train, \n",
    "                norm_x_test,\n",
    "                epochs=10,\n",
    "                batch_size=512,\n",
    "                shuffle=True\n",
    "            )\n",
    "else:\n",
    "    conv_history = conv_model.get_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(conv_model_params_path) or not os.path.exists(conv_model_weights_path):\n",
    "    conv_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoder = conv_model.get_encoder()\n",
    "conv_decoder = conv_model.get_decoder()\n",
    "conv_autoencoder = conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(conv_history.history['loss'])\n",
    "plt.plot(conv_history.history['val_loss'])\n",
    "plt.title('Model loss (Convoluted)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Calcolo delle statistiche dello spazio latente\n",
    "# (utilizzato per il sampling)\n",
    "# -------------------------------\n",
    "conv_latent_reps = conv_encoder.predict(norm_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_latent_mean = np.mean(conv_latent_reps, axis=0)\n",
    "conv_latent_std = np.std(conv_latent_reps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoded_img = np.random.normal(loc=conv_latent_mean, scale=conv_latent_std, size=(1,latent_space_dim))\n",
    "# Decodifica per ottenere la ricostruzione\n",
    "conv_decoded_img = conv_decoder.predict(conv_encoded_img)\n",
    "# Genera una nuova immagine\n",
    "plot_img(conv_decoded_img[0], figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encoding_tsne(conv_encoder, norm_x_test, y_test, sample_size=1000, title=f\"t-SNE projection of the latent space (Convoluted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function for Variational Autoencoders\n",
    "\n",
    "$Loss = \\alpha \\cdot RMSE + KL$\n",
    "\n",
    "* $RMSE$  \n",
    "Root mean squared error. It's the Reconstruction error\n",
    "* $\\alpha$ \n",
    "Reconstruction loss weight\n",
    "* $KL$  \n",
    "Kullback-Leibler divergence. It measures the _difference_ between a multivariate normal distribution and a multivariate standard normal distribution.  \n",
    "A standard normal distribution is a normal distribution with mean ($\\mu$) equal to 0 and standard deviation ($\\sigma$) equal to 1\n",
    "\n",
    "Kullback-Leibler divergence (Closed-form)  \n",
    "$D_{KL} (N(\\mu,\\sigma) || N(0,1))= \\frac{1}{2} \\sum \\left(1+\\log(\\sigma^2)-\\mu^2-\\sigma^2\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_input_shape = (norm_x_train.shape[1:][0], norm_x_train.shape[1:][1], 1)\n",
    "vae_filters=(32, 64, 64, 64)\n",
    "vae_activations=('relu', 'relu', 'relu', 'relu')\n",
    "vae_kernels=(3, 3, 3, 3)\n",
    "vae_strides=(1, 2, 2, 1)\n",
    "vae_latent_space_dim=2\n",
    "\n",
    "vae_model_type = VariationalAutoencoder.__name__\n",
    "\n",
    "vae_model_params_path = os.path.join(model_path, f\"{vae_model_type}_{model_name}.parameters.pkl\")\n",
    "vae_model_weights_path = os.path.join(model_path, f\"{vae_model_type}_{model_name}.weights.h5\")\n",
    "if not os.path.exists(vae_model_params_path) or not os.path.exists(vae_model_weights_path):\n",
    "    vae_model = VariationalAutoencoder(\n",
    "        input_shape=vae_input_shape, \n",
    "        filters=vae_filters, \n",
    "        kernels=vae_kernels, \n",
    "        strides=vae_strides, \n",
    "        activations=vae_activations,\n",
    "        latent_space_dim=vae_latent_space_dim,\n",
    "        model_name=model_name,\n",
    "        reconstruction_loss_weight=1\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.get(\"Adam\")\n",
    "    optimizer.learning_rate.assign(.001)\n",
    "    vae_model.compile(optimizer=optimizer)\n",
    "else:\n",
    "    vae_model = VariationalAutoencoder.load(model_path, model_name)\n",
    "\n",
    "#vae_model.print_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.run_functions_eagerly(False)\n",
    "if not os.path.exists(vae_model_params_path) or not os.path.exists(vae_model_weights_path):\n",
    "    vae_history = vae_model.train(\n",
    "                norm_x_train, \n",
    "                norm_x_test,\n",
    "                epochs=20,\n",
    "                batch_size=512,\n",
    "                shuffle=True\n",
    "            )\n",
    "else:\n",
    "    vae_history = vae_model.get_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(vae_model_params_path) or not os.path.exists(vae_model_weights_path):\n",
    "    vae_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder = vae_model.get_encoder()\n",
    "vae_decoder = vae_model.get_decoder()\n",
    "vae_autoencoder = vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(vae_history.history['loss'])\n",
    "plt.plot(vae_history.history['val_loss'])\n",
    "plt.title('Model loss (VAE)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Calcolo delle statistiche dello spazio latente\n",
    "# (utilizzato per il sampling)\n",
    "# -------------------------------\n",
    "vae_latent_reps, _, _ = vae_encoder.predict(norm_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_latent_mean = np.mean(vae_latent_reps, axis=0)\n",
    "vae_latent_std = np.std(vae_latent_reps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoded_img = np.random.normal(loc=vae_latent_mean, scale=vae_latent_std, size=(1,latent_space_dim))\n",
    "# Decodifica per ottenere la ricostruzione\n",
    "vae_decoded_img = vae_decoder.predict(vae_encoded_img)\n",
    "# Genera una nuova immagine\n",
    "plot_img(vae_decoded_img[0], figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encoding_tsne(vae_encoder, norm_x_test, y_test, sample_size=1000, title=f\"t-SNE projection of the latent space (Variational Encoder)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Spaces Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encoding_tsne(vanilla_encoder, flatten_x_train, y_train, sample_size=1000, title=f\"t-SNE projection of the latent space (Vanilla Encoder)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encoding_tsne(conv_encoder, norm_x_train, y_train, sample_size=1000, title=f\"t-SNE projection of the latent space (Convoluted Encoder)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encoding_tsne(vae_encoder, norm_x_train, y_train, sample_size=1000, title=f\"t-SNE projection of the latent space (Variational Encoder)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
