{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c72a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d1d01",
   "metadata": {},
   "source": [
    "### PyTorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f195f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0627e3",
   "metadata": {},
   "source": [
    "### Cuda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff015308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  6 13:22:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        Off |   00000000:01:00.0  On |                  N/A |\n",
      "| 47%   39C    P8             29W /  350W |   10426MiB /  12288MiB |     25%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2414      G   /usr/lib/xorg/Xorg                            169MiB |\n",
      "|    0   N/A  N/A      2563      G   /usr/bin/gnome-shell                           56MiB |\n",
      "|    0   N/A  N/A      4409      G   ...erProcess --variations-seed-version         29MiB |\n",
      "|    0   N/A  N/A      6410      G   ...erProcess --variations-seed-version         98MiB |\n",
      "|    0   N/A  N/A     11639      G   /usr/lib/firefox/firefox                      128MiB |\n",
      "|    0   N/A  N/A     85641      C   ...ri/.venv/llms-evaluation/bin/python       9920MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371a75e",
   "metadata": {},
   "source": [
    "### PyTorch default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b58dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(torch.get_default_dtype())\n",
    "display(torch.get_default_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d395b43",
   "metadata": {},
   "source": [
    "### Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3218fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_0 ndim: 0, shape torch.Size([]), requires_grad False, dtype torch.float32 device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0038)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_gpu_0 ndim: 0, shape torch.Size([]), requires_grad False, dtype torch.float32 device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9720, device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tens_0 = torch.rand(size=(), dtype=None, device=None, requires_grad=False)\n",
    "print(f\"tens_0 ndim: {tens_0.ndim}, shape {tens_0.shape}, requires_grad {tens_0.requires_grad}, dtype {tens_0.dtype} device {tens_0.device}\")\n",
    "display(tens_0)\n",
    "\n",
    "tens_gpu_0 = torch.rand(size=(), dtype=None, device='cuda', requires_grad=False)\n",
    "print(f\"tens_gpu_0 ndim: {tens_gpu_0.ndim}, shape {tens_gpu_0.shape}, requires_grad {tens_gpu_0.requires_grad}, dtype {tens_gpu_0.dtype} device {tens_gpu_0.device}\")\n",
    "display(tens_gpu_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c400a",
   "metadata": {},
   "source": [
    "### Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7b9079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_1 ndim: 1, shape torch.Size([3]), requires_grad False, dtype torch.float32 device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4049, 0.7345, 0.3481])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_gpu_1 ndim: 1, shape torch.Size([3]), requires_grad False, dtype torch.float32 device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9028, 0.2098, 0.7335], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tens_1 = torch.rand(size=(3,), dtype=None, device=None, requires_grad=False)\n",
    "print(f\"tens_1 ndim: {tens_1.ndim}, shape {tens_1.shape}, requires_grad {tens_1.requires_grad}, dtype {tens_1.dtype} device {tens_1.device}\")\n",
    "display(tens_1)\n",
    "\n",
    "tens_gpu_1 = torch.rand(size=(3,), dtype=None, device='cuda', requires_grad=False)\n",
    "print(f\"tens_gpu_1 ndim: {tens_gpu_1.ndim}, shape {tens_gpu_1.shape}, requires_grad {tens_gpu_1.requires_grad}, dtype {tens_gpu_1.dtype} device {tens_gpu_1.device}\")\n",
    "display(tens_gpu_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6267e174",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09427bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_2 ndim: 2, shape torch.Size([3, 4]), requires_grad False, dtype torch.float32, device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6560, 0.7023, 0.5975, 0.2189],\n",
       "        [0.1764, 0.7195, 0.8631, 0.6895],\n",
       "        [0.0937, 0.3998, 0.9137, 0.6023]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_gpu_2 ndim: 2, shape torch.Size([3, 4]), requires_grad False, dtype torch.float32 device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0885, 0.4325, 0.2230, 0.0068],\n",
       "        [0.8494, 0.1105, 0.0896, 0.9383],\n",
       "        [0.6968, 0.5547, 0.1479, 0.0256]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tens_2 = torch.rand(size=(3, 4), dtype=None, device=None)\n",
    "print(f\"tens_2 ndim: {tens_2.ndim}, shape {tens_2.shape}, requires_grad {tens_2.requires_grad}, dtype {tens_2.dtype}, device {tens_2.device}\")\n",
    "display(tens_2)\n",
    "\n",
    "tens_gpu_2 = torch.rand(size=(3, 4), dtype=None, device='cuda', requires_grad=False)\n",
    "print(f\"tens_gpu_2 ndim: {tens_gpu_2.ndim}, shape {tens_gpu_2.shape}, requires_grad {tens_gpu_2.requires_grad}, dtype {tens_gpu_2.dtype} device {tens_gpu_2.device}\")\n",
    "display(tens_gpu_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e045c",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf5ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_3 ndim: 3, shape torch.Size([5, 4, 3]), requires_grad False, dtype torch.float32, device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6127, 0.4937, 0.3737],\n",
       "         [0.1833, 0.2508, 0.3210],\n",
       "         [0.9242, 0.3690, 0.3014],\n",
       "         [0.6134, 0.7216, 0.5169]],\n",
       "\n",
       "        [[0.9880, 0.6350, 0.7963],\n",
       "         [0.2793, 0.4112, 0.8320],\n",
       "         [0.5989, 0.4759, 0.0760],\n",
       "         [0.8501, 0.5075, 0.9394]],\n",
       "\n",
       "        [[0.1370, 0.7787, 0.1632],\n",
       "         [0.6403, 0.3949, 0.6311],\n",
       "         [0.1667, 0.1497, 0.0855],\n",
       "         [0.4844, 0.3968, 0.9076]],\n",
       "\n",
       "        [[0.2653, 0.5209, 0.5230],\n",
       "         [0.9148, 0.3693, 0.4530],\n",
       "         [0.0183, 0.0986, 0.2594],\n",
       "         [0.5154, 0.1977, 0.9639]],\n",
       "\n",
       "        [[0.8786, 0.4120, 0.1120],\n",
       "         [0.4771, 0.1534, 0.8716],\n",
       "         [0.4368, 0.7637, 0.7028],\n",
       "         [0.4131, 0.7037, 0.8118]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_gpu_3 ndim: 3, shape torch.Size([5, 4, 3]), requires_grad False, dtype torch.float32 device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3652, 0.3344, 0.0765],\n",
       "         [0.1005, 0.1281, 0.6179],\n",
       "         [0.7534, 0.0158, 0.5803],\n",
       "         [0.5402, 0.6321, 0.5069]],\n",
       "\n",
       "        [[0.2517, 0.6963, 0.8803],\n",
       "         [0.2986, 0.1276, 0.2859],\n",
       "         [0.3521, 0.2503, 0.8741],\n",
       "         [0.8774, 0.6897, 0.1239]],\n",
       "\n",
       "        [[0.3514, 0.1734, 0.2755],\n",
       "         [0.6714, 0.3219, 0.6329],\n",
       "         [0.3219, 0.6464, 0.7811],\n",
       "         [0.2872, 0.1971, 0.1406]],\n",
       "\n",
       "        [[0.7809, 0.0637, 0.7697],\n",
       "         [0.4411, 0.7388, 0.6237],\n",
       "         [0.6517, 0.7068, 0.4645],\n",
       "         [0.0871, 0.9812, 0.8184]],\n",
       "\n",
       "        [[0.9034, 0.1986, 0.8990],\n",
       "         [0.7193, 0.3138, 0.6373],\n",
       "         [0.6011, 0.7158, 0.6255],\n",
       "         [0.1629, 0.3631, 0.2973]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tens_3 = torch.rand(size=(5, 4, 3), dtype=None, device=None)\n",
    "print(f\"tens_3 ndim: {tens_3.ndim}, shape {tens_3.shape}, requires_grad {tens_3.requires_grad}, dtype {tens_3.dtype}, device {tens_3.device}\")\n",
    "display(tens_3)\n",
    "\n",
    "tens_gpu_3 = torch.rand(size=(5, 4, 3), dtype=None, device='cuda', requires_grad=False)\n",
    "print(f\"tens_gpu_3 ndim: {tens_gpu_3.ndim}, shape {tens_gpu_3.shape}, requires_grad {tens_gpu_3.requires_grad}, dtype {tens_gpu_3.dtype} device {tens_gpu_3.device}\")\n",
    "display(tens_gpu_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667ac4f",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be33c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens_2a = torch.rand(size=(4,2), dtype=torch.float32, device='cuda', requires_grad=False)\n",
    "tens_2b = torch.rand(size=(4,2), dtype=torch.float32, device='cuda', requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e451e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_2a ndim: 2, shape torch.Size([4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2716, 0.2912],\n",
       "        [0.2154, 0.1459],\n",
       "        [0.8024, 0.0452],\n",
       "        [0.7345, 0.9042]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_2b ndim: 2, shape torch.Size([4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6902, 0.2744],\n",
       "        [0.2109, 0.2656],\n",
       "        [0.5940, 0.6142],\n",
       "        [0.8133, 0.8926]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_2b_T ndim: 2, shape torch.Size([2, 4]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6902, 0.2109, 0.5940, 0.8133],\n",
       "        [0.2744, 0.2656, 0.6142, 0.8926]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_2_sum ndim: 2, shape torch.Size([4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9618, 0.5656],\n",
       "        [0.4262, 0.4116],\n",
       "        [1.3965, 0.6594],\n",
       "        [1.5478, 1.7968]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_2_mul ndim: 2, shape torch.Size([4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1874, 0.0799],\n",
       "        [0.0454, 0.0388],\n",
       "        [0.4767, 0.0277],\n",
       "        [0.5974, 0.8071]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_2_matmul ndim: 2, shape torch.Size([4, 4]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2674, 0.1346, 0.3402, 0.4808],\n",
       "        [0.1887, 0.0842, 0.2176, 0.3054],\n",
       "        [0.5662, 0.1812, 0.5044, 0.6930],\n",
       "        [0.7550, 0.3951, 0.9917, 1.4045]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"tens_2a ndim: {tens_2a.ndim}, shape {tens_2a.shape}, requires_grad {tens_2a.requires_grad}, dtype {tens_2a.dtype}, device {tens_2a.device}\")\n",
    "display(tens_2a)\n",
    "print(f\"tens_2b ndim: {tens_2b.ndim}, shape {tens_2b.shape}, requires_grad {tens_2b.requires_grad}, dtype {tens_2b.dtype}, device {tens_2b.device}\")\n",
    "display(tens_2b)\n",
    "\n",
    "tens_2b_T = tens_2b.transpose(1,0)\n",
    "print(f\"tens_2b_T ndim: {tens_2b_T.ndim}, shape {tens_2b_T.shape}, requires_grad {tens_2b_T.requires_grad}, dtype {tens_2b_T.dtype}, device {tens_2b_T.device}\")\n",
    "display(tens_2b_T)\n",
    "\n",
    "tens_2_sum = tens_2a + tens_2b\n",
    "tens_2_mul = tens_2a * tens_2b\n",
    "tens_2_matmul = torch.matmul(tens_2a, tens_2b_T)\n",
    "\n",
    "print(f\"tens_2_sum ndim: {tens_2_sum.ndim}, shape {tens_2_sum.shape}, requires_grad {tens_2_sum.requires_grad}, dtype {tens_2_sum.dtype}, device {tens_2_sum.device}\")\n",
    "display(tens_2_sum)\n",
    "print(f\"tens_2_mul ndim: {tens_2_mul.ndim}, shape {tens_2_mul.shape}, requires_grad {tens_2_mul.requires_grad}, dtype {tens_2_mul.dtype}, device {tens_2_mul.device}\")\n",
    "display(tens_2_mul)\n",
    "print(f\"tens_2_matmul ndim: {tens_2_matmul.ndim}, shape {tens_2_matmul.shape}, requires_grad {tens_2_matmul.requires_grad}, dtype {tens_2_matmul.dtype}, device {tens_2_matmul.device}\")\n",
    "display(tens_2_matmul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bef6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens_3a = torch.rand(size=(3,4,2), dtype=torch.float32, device='cuda', requires_grad=False)\n",
    "tens_3b = torch.rand(size=(3,4,2), dtype=torch.float32, device='cuda', requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61383b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_3a ndim: 3, shape torch.Size([3, 4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5328, 0.2786],\n",
       "         [0.3585, 0.3866],\n",
       "         [0.0892, 0.1502],\n",
       "         [0.7887, 0.1483]],\n",
       "\n",
       "        [[0.5356, 0.4796],\n",
       "         [0.2085, 0.9336],\n",
       "         [0.5298, 0.2109],\n",
       "         [0.9995, 0.3354]],\n",
       "\n",
       "        [[0.1678, 0.3359],\n",
       "         [0.1941, 0.2531],\n",
       "         [0.3602, 0.3886],\n",
       "         [0.7860, 0.2344]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_3b ndim: 3, shape torch.Size([3, 4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0631, 0.4734],\n",
       "         [0.3554, 0.2453],\n",
       "         [0.6107, 0.7567],\n",
       "         [0.9150, 0.9248]],\n",
       "\n",
       "        [[0.8995, 0.6415],\n",
       "         [0.8965, 0.4093],\n",
       "         [0.3902, 0.6331],\n",
       "         [0.8656, 0.4075]],\n",
       "\n",
       "        [[0.4163, 0.9704],\n",
       "         [0.8618, 0.4396],\n",
       "         [0.0889, 0.1247],\n",
       "         [0.5987, 0.2378]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_3b_T ndim: 3, shape torch.Size([3, 2, 4]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0631, 0.3554, 0.6107, 0.9150],\n",
       "         [0.4734, 0.2453, 0.7567, 0.9248]],\n",
       "\n",
       "        [[0.8995, 0.8965, 0.3902, 0.8656],\n",
       "         [0.6415, 0.4093, 0.6331, 0.4075]],\n",
       "\n",
       "        [[0.4163, 0.8618, 0.0889, 0.5987],\n",
       "         [0.9704, 0.4396, 0.1247, 0.2378]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_3_sum ndim: 3, shape torch.Size([3, 4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5959, 0.7520],\n",
       "         [0.7139, 0.6319],\n",
       "         [0.6999, 0.9069],\n",
       "         [1.7036, 1.0731]],\n",
       "\n",
       "        [[1.4351, 1.1210],\n",
       "         [1.1050, 1.3429],\n",
       "         [0.9200, 0.8440],\n",
       "         [1.8651, 0.7430]],\n",
       "\n",
       "        [[0.5840, 1.3063],\n",
       "         [1.0559, 0.6926],\n",
       "         [0.4492, 0.5133],\n",
       "         [1.3847, 0.4722]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_3_mul ndim: 3, shape torch.Size([3, 4, 2]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0336, 0.1319],\n",
       "         [0.1274, 0.0948],\n",
       "         [0.0545, 0.1136],\n",
       "         [0.7216, 0.1371]],\n",
       "\n",
       "        [[0.4818, 0.3076],\n",
       "         [0.1870, 0.3821],\n",
       "         [0.2067, 0.1335],\n",
       "         [0.8652, 0.1367]],\n",
       "\n",
       "        [[0.0698, 0.3259],\n",
       "         [0.1673, 0.1112],\n",
       "         [0.0320, 0.0485],\n",
       "         [0.4706, 0.0557]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tens_3_matmul ndim: 3, shape torch.Size([3, 4, 4]), requires_grad False, dtype torch.float32, device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1655, 0.2577, 0.5362, 0.7452],\n",
       "         [0.2056, 0.2223, 0.5115, 0.6856],\n",
       "         [0.0767, 0.0685, 0.1681, 0.2205],\n",
       "         [0.1200, 0.3166, 0.5938, 0.8587]],\n",
       "\n",
       "        [[0.7894, 0.6765, 0.5126, 0.6591],\n",
       "         [0.7864, 0.5691, 0.6724, 0.5610],\n",
       "         [0.6118, 0.5613, 0.3402, 0.5446],\n",
       "         [1.1142, 1.0333, 0.6023, 1.0019]],\n",
       "\n",
       "        [[0.3958, 0.2922, 0.0568, 0.1803],\n",
       "         [0.3264, 0.2785, 0.0488, 0.1764],\n",
       "         [0.5270, 0.4812, 0.0805, 0.3081],\n",
       "         [0.5546, 0.7804, 0.0991, 0.5263]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"tens_3a ndim: {tens_3a.ndim}, shape {tens_3a.shape}, requires_grad {tens_3a.requires_grad}, dtype {tens_3a.dtype}, device {tens_3a.device}\")\n",
    "display(tens_3a)\n",
    "print(f\"tens_3b ndim: {tens_3b.ndim}, shape {tens_3b.shape}, requires_grad {tens_3b.requires_grad}, dtype {tens_3b.dtype}, device {tens_3b.device}\")\n",
    "display(tens_3b)\n",
    "\n",
    "tens_3b_T = tens_3b.transpose(2,1)\n",
    "print(f\"tens_3b_T ndim: {tens_3b_T.ndim}, shape {tens_3b_T.shape}, requires_grad {tens_3b_T.requires_grad}, dtype {tens_3b_T.dtype}, device {tens_3b_T.device}\")\n",
    "display(tens_3b_T)\n",
    "\n",
    "tens_3_sum = tens_3a + tens_3b\n",
    "tens_3_mul = tens_3a * tens_3b\n",
    "tens_3_matmul = torch.matmul(tens_3a, tens_3b_T)\n",
    "\n",
    "print(f\"tens_3_sum ndim: {tens_3_sum.ndim}, shape {tens_3_sum.shape}, requires_grad {tens_3_sum.requires_grad}, dtype {tens_3_sum.dtype}, device {tens_3_sum.device}\")\n",
    "display(tens_3_sum)\n",
    "print(f\"tens_3_mul ndim: {tens_3_mul.ndim}, shape {tens_3_mul.shape}, requires_grad {tens_3_mul.requires_grad}, dtype {tens_3_mul.dtype}, device {tens_3_mul.device}\")\n",
    "display(tens_3_mul)\n",
    "print(f\"tens_3_matmul ndim: {tens_3_matmul.ndim}, shape {tens_3_matmul.shape}, requires_grad {tens_3_matmul.requires_grad}, dtype {tens_3_matmul.dtype}, device {tens_3_matmul.device}\")\n",
    "display(tens_3_matmul)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
